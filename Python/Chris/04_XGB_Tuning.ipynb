{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import skutils\n",
    "import pandas as pd\n",
    "\n",
    "TRAIN_DATA = \"../../data/train.csv\"\n",
    "TEST_DATA = \"../../data/test.csv\"\n",
    "\n",
    "# Load the training data\n",
    "train = pd.read_csv(TRAIN_DATA)\n",
    "\n",
    "# Load the testing data\n",
    "test = pd.read_csv(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get uniques\n",
    "uniques = train.apply(lambda x: len(x.unique()))\n",
    "\n",
    "def transform(data, threshold_unimportant=0.0000001):\n",
    "    \n",
    "    cols_emtpy = list(uniques[uniques == 1].index.values)\n",
    "    \n",
    "    # We have to remove the correlated ones by hand\n",
    "    # because there can be multiple correlations with one column\n",
    "    cols_correlated = [\n",
    "        'ind_var1', 'ind_var1_0',\n",
    "        'ind_var5',\n",
    "        'ind_var6', 'ind_var6_0', 'num_var6',\n",
    "        'ind_var8', 'ind_var8_0',\n",
    "        'ind_var12',\n",
    "        'ind_var13_corto', 'ind_var13_corto_0', 'ind_var13_medio', 'ind_var13_medio_0',\n",
    "        'ind_var18', 'ind_var18_0', 'num_var18', 'num_var18_0',\n",
    "        'ind_var20', 'ind_var20_0',\n",
    "        'ind_var29', 'ind_var29_0',\n",
    "        'ind_var24', 'ind_var24_0',\n",
    "        'ind_var25_0', 'num_var25_0',\n",
    "        'ind_var26_0', 'num_var26_0',\n",
    "        'ind_var32_0', 'num_var32_0',\n",
    "        'ind_var34', 'ind_var34_0', 'num_var34', 'num_var34_0',\n",
    "        'ind_var37_0', 'num_var37_0',\n",
    "        'ind_var39',\n",
    "        'ind_var40', 'num_var40',\n",
    "        'ind_var44',\n",
    "        'num_var29_0',\n",
    "        'num_var13_medio', 'num_var13_medio_0',\n",
    "        'num_var7_emit_ult1',\n",
    "        'num_var39',\n",
    "        'num_var40_0',\n",
    "        'num_var44_0',\n",
    "        'saldo_var6',\n",
    "        'saldo_var18',\n",
    "        'saldo_var13_medio',\n",
    "        'saldo_medio_var17_ult3',\n",
    "        'saldo_medio_var33_ult1',\n",
    "        'delta_imp_aport_var13_1y3', 'delta_imp_reemb_var13_1y3', 'delta_num_reemb_var13_1y3',\n",
    "        'delta_imp_aport_var17_1y3', 'delta_imp_reemb_var17_1y3', 'delta_num_trasp_var17_in_1y3', 'delta_num_trasp_var17_out_1y3',\n",
    "        'delta_imp_aport_var33_1y3', 'delta_imp_reemb_var33_1y3', 'delta_num_reemb_var33_1y3', 'delta_num_trasp_var33_out_1y3',\n",
    "        'delta_imp_compra_var44_1y3', 'delta_imp_venta_var44_1y3',\n",
    "        'delta_imp_trasp_var17_in_1y3', 'delta_imp_trasp_var17_out_1y3',\n",
    "        'delta_imp_trasp_var33_in_1y3', 'delta_imp_trasp_var33_out_1y3',\n",
    "        'imp_reemb_var17_hace3',\n",
    "        'imp_reemb_var33_ult1', 'imp_trasp_var33_out_ult1',\n",
    "        'num_med_var45_ult3',\n",
    "        'imp_op_var39_efect_ult1',\n",
    "        'imp_op_var39_efect_ult3',\n",
    "        'imp_op_var39_ult1',\n",
    "        'imp_amort_var18_ult1',\n",
    "        'saldo_medio_var17_hace3', 'saldo_medio_var17_ult1',\n",
    "        'saldo_medio_var13_medio_ult3',\n",
    "    ]\n",
    "\n",
    "    # Extract the ids\n",
    "    ids = data['ID']\n",
    "    \n",
    "    # Extract the data\n",
    "    X = data.drop(['ID'] + cols_emtpy + cols_correlated,  axis=1)\n",
    "    if 'TARGET' in data.columns:\n",
    "        X.drop('TARGET', axis=1, inplace=True)\n",
    "\n",
    "    # Extract the labels\n",
    "    y = data['TARGET'] if 'TARGET' in data.columns else None\n",
    "    \n",
    "    return ids, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Learning Rates with decay function\n",
    "def learning_rates(steps, start=1, end=0, start_exp_x=0.0, end_exp_x=7.0):\n",
    "    return end + np.exp(-np.linspace(start_exp_x, end_exp_x, steps)) * (start - end)\n",
    "\n",
    "def cross_validate_xgb(X_train, y_train, parms, fit_params={}, folds=None, scorer=roc_auc_score):\n",
    "\n",
    "    if folds is None:\n",
    "        folds = skutils.folds(y_train, n_folds=4, stratified=True)\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, test_idx in folds:\n",
    "\n",
    "        clf = xgb.XGBClassifier(**parms)\n",
    "        \n",
    "        # Needs latest XGBoost from chaosmail\n",
    "        # https://github.com/chaosmail/xgboost\n",
    "        # Build Instructions: https://github.com/dmlc/xgboost/blob/master/doc/build.md\n",
    "        # https://github.com/dmlc/xgboost/pull/1018\n",
    "        clf.fit(X_train.values[train_idx], y_train.values[train_idx], verbose=False, **fit_params)\n",
    "        \n",
    "        # Predict the output\n",
    "        y_predict = clf.predict_proba(X_train.values[test_idx], ntree_limit=clf.best_iteration)[:,1]\n",
    "        \n",
    "        # Compute a score\n",
    "        scores.append(scorer(y_train.values[test_idx], y_predict))\n",
    "    \n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Transform the training data\n",
    "Ids_train, X, y = transform(train)\n",
    "\n",
    "folds = ShuffleSplit(len(y), random_state=2, n_iter=20, test_size=0.1)\n",
    "\n",
    "for train_idx, test_idx in folds:\n",
    "    X_train_, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "The more happy customers in our training set, the more the classifier will overfit for this target group. Hence we need to remove some of thos values from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fzeros = 0.82\n",
    "X_train, y_train = skutils.random_subset(X_train_, y_train_, dims=[(0, fzeros), (1, 1.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a XGB Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rates\n",
    "\n",
    "Instead of a simple Learning Rates, we want to have fast converging and smooth decay - hence we just build up our custom learning rates function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f33191c6198>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f331ab38898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning rates\n",
    "steps = 20\n",
    "fig = plt.figure()\n",
    "plt.plot(np.linspace(0, 1, steps), learning_rates(steps, start=0.1, end=0.02), marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# In the end we will use this amount of estimators\n",
    "n_total_estimators = 500\n",
    "n_cv_estimators = 250\n",
    "seed = 42\n",
    "\n",
    "params = {\n",
    "    'max_depth': hp.quniform('max_depth', 2, 10, 1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.9, 1),\n",
    "    'learning_rate_start': hp.uniform('learning_rate_start', 0.1, 0.3),\n",
    "    'learning_rate_end': hp.uniform('learning_rate_end', 0.01, 0.1),\n",
    "    'seed': hp.quniform('seed', 1, 1000000),\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    'early_stopping_rounds': 20,\n",
    "    'eval_metric': 'auc',\n",
    "    'eval_set': [(X_test.values, y_test.values)],\n",
    "}\n",
    "# eval_set: set that is used for watching the training performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the parameters of XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, rand, hp, STATUS_OK, Trials\n",
    "\n",
    "folds = skutils.folds(y_train, n_folds=4, stratified=True, random_state=seed)\n",
    "\n",
    "def objective(params):\n",
    "        \n",
    "    cv_params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'min_child_weight': params['min_child_weight'],\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'n_estimators': n_cv_estimators,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    \n",
    "    def iter_learning_rates(i, n): \n",
    "        return learning_rates(\n",
    "            n_total_estimators, start=params['learning_rate_start'], end=params['learning_rate_end']\n",
    "        )[i]\n",
    "        \n",
    "    fit_params['learning_rates'] = iter_learning_rates\n",
    "    \n",
    "    score_mean, score_std = cross_validate_xgb(X_train, y_train, cv_params, fit_params, folds=folds)\n",
    "    \n",
    "    print(\"Cross validation test-auc-mean score %.8f (+- %.8f)\" % (score_mean, score_std))\n",
    "\n",
    "    return {\n",
    "        'loss': 1 - score_mean,\n",
    "        'loss_variance': score_std**2,\n",
    "        'status': STATUS_OK,\n",
    "        \n",
    "        #'test-auc-mean': scores['test-auc-mean'],\n",
    "        #'test-auc-std': scores['test-auc-std'],\n",
    "        #'train-auc-mean': scores['train-auc-mean'],\n",
    "        #'train-auc-std': scores['train-auc-std'],\n",
    "    } \n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# Needs latest hyperopt from chaosmail\n",
    "# https://github.com/chaosmail/hyperopt\n",
    "# https://github.com/hyperopt/hyperopt/issues/234\n",
    "best = fmin(fn=objective, space=params, algo=rand.suggest, max_evals=100, trials=trials)\n",
    "\n",
    "# Print the best result\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9840611732060847,\n",
       " 'learning_rate_end': 0.08303127679504986,\n",
       " 'learning_rate_start': 0.11158443875324964,\n",
       " 'max_depth': 4.0,\n",
       " 'min_child_weight': 4.0,\n",
       " 'subsample': 0.8057646474356563}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ooh Hack, I minimized the AUC score instead of minimizing the loss!\n",
    "# Now i need to find the max and set it manualy\n",
    "sorted_trials = sorted(trials.trials, key=lambda trial: trial['result']['loss'])\n",
    "\n",
    "scores = sorted_trials[0]['result']\n",
    "\n",
    "print(\"Cross validation test-auc-mean score %.8f (+- %.8f)\" % (scores['acu-test-mean'], scores['acu-test-std']))\n",
    "print(\"Cross validation train-auc-mean score %.8f (+- %.8f)\" % (scores['acu-train-mean'], scores['acu-train-std']))\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Private Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "\n",
      "[0]\tvalidation_0-auc:0.816003\n",
      "\n",
      "[1]\tvalidation_0-auc:0.823203\n",
      "\n",
      "[2]\tvalidation_0-auc:0.826731\n",
      "\n",
      "[3]\tvalidation_0-auc:0.828860\n",
      "\n",
      "[4]\tvalidation_0-auc:0.829577\n",
      "\n",
      "[5]\tvalidation_0-auc:0.831272\n",
      "\n",
      "[6]\tvalidation_0-auc:0.831710\n",
      "\n",
      "[7]\tvalidation_0-auc:0.832975\n",
      "\n",
      "[8]\tvalidation_0-auc:0.833394\n",
      "\n",
      "[9]\tvalidation_0-auc:0.834003\n",
      "\n",
      "[10]\tvalidation_0-auc:0.834220\n",
      "\n",
      "[11]\tvalidation_0-auc:0.834908\n",
      "\n",
      "[12]\tvalidation_0-auc:0.836941\n",
      "\n",
      "[13]\tvalidation_0-auc:0.836239\n",
      "\n",
      "[14]\tvalidation_0-auc:0.836225\n",
      "\n",
      "[15]\tvalidation_0-auc:0.835456\n",
      "\n",
      "[16]\tvalidation_0-auc:0.834879\n",
      "\n",
      "[17]\tvalidation_0-auc:0.835704\n",
      "\n",
      "[18]\tvalidation_0-auc:0.835653\n",
      "\n",
      "[19]\tvalidation_0-auc:0.835500\n",
      "\n",
      "[20]\tvalidation_0-auc:0.836221\n",
      "\n",
      "[21]\tvalidation_0-auc:0.835806\n",
      "\n",
      "[22]\tvalidation_0-auc:0.836845\n",
      "\n",
      "[23]\tvalidation_0-auc:0.836195\n",
      "\n",
      "[24]\tvalidation_0-auc:0.836413\n",
      "\n",
      "[25]\tvalidation_0-auc:0.836158\n",
      "\n",
      "[26]\tvalidation_0-auc:0.836486\n",
      "\n",
      "[27]\tvalidation_0-auc:0.836761\n",
      "\n",
      "[28]\tvalidation_0-auc:0.836701\n",
      "\n",
      "[29]\tvalidation_0-auc:0.837387\n",
      "\n",
      "[30]\tvalidation_0-auc:0.837511\n",
      "\n",
      "[31]\tvalidation_0-auc:0.837588\n",
      "\n",
      "[32]\tvalidation_0-auc:0.838173\n",
      "\n",
      "[33]\tvalidation_0-auc:0.839456\n",
      "\n",
      "[34]\tvalidation_0-auc:0.838991\n",
      "\n",
      "[35]\tvalidation_0-auc:0.839568\n",
      "\n",
      "[36]\tvalidation_0-auc:0.840243\n",
      "\n",
      "[37]\tvalidation_0-auc:0.841033\n",
      "\n",
      "[38]\tvalidation_0-auc:0.841026\n",
      "\n",
      "[39]\tvalidation_0-auc:0.841494\n",
      "\n",
      "[40]\tvalidation_0-auc:0.841771\n",
      "\n",
      "[41]\tvalidation_0-auc:0.842244\n",
      "\n",
      "[42]\tvalidation_0-auc:0.842158\n",
      "\n",
      "[43]\tvalidation_0-auc:0.842498\n",
      "\n",
      "[44]\tvalidation_0-auc:0.842477\n",
      "\n",
      "[45]\tvalidation_0-auc:0.842488\n",
      "\n",
      "[46]\tvalidation_0-auc:0.842091\n",
      "\n",
      "[47]\tvalidation_0-auc:0.842446\n",
      "\n",
      "[48]\tvalidation_0-auc:0.842463\n",
      "\n",
      "[49]\tvalidation_0-auc:0.842543\n",
      "\n",
      "[50]\tvalidation_0-auc:0.842426\n",
      "\n",
      "[51]\tvalidation_0-auc:0.842488\n",
      "\n",
      "[52]\tvalidation_0-auc:0.842571\n",
      "\n",
      "[53]\tvalidation_0-auc:0.842752\n",
      "\n",
      "[54]\tvalidation_0-auc:0.843181\n",
      "\n",
      "[55]\tvalidation_0-auc:0.843043\n",
      "\n",
      "[56]\tvalidation_0-auc:0.843038\n",
      "\n",
      "[57]\tvalidation_0-auc:0.843338\n",
      "\n",
      "[58]\tvalidation_0-auc:0.843653\n",
      "\n",
      "[59]\tvalidation_0-auc:0.843713\n",
      "\n",
      "[60]\tvalidation_0-auc:0.843947\n",
      "\n",
      "[61]\tvalidation_0-auc:0.844111\n",
      "\n",
      "[62]\tvalidation_0-auc:0.844000\n",
      "\n",
      "[63]\tvalidation_0-auc:0.844034\n",
      "\n",
      "[64]\tvalidation_0-auc:0.844041\n",
      "\n",
      "[65]\tvalidation_0-auc:0.844184\n",
      "\n",
      "[66]\tvalidation_0-auc:0.844385\n",
      "\n",
      "[67]\tvalidation_0-auc:0.844502\n",
      "\n",
      "[68]\tvalidation_0-auc:0.844695\n",
      "\n",
      "[69]\tvalidation_0-auc:0.844399\n",
      "\n",
      "[70]\tvalidation_0-auc:0.844517\n",
      "\n",
      "[71]\tvalidation_0-auc:0.844578\n",
      "\n",
      "[72]\tvalidation_0-auc:0.844509\n",
      "\n",
      "[73]\tvalidation_0-auc:0.844514\n",
      "\n",
      "[74]\tvalidation_0-auc:0.844751\n",
      "\n",
      "[75]\tvalidation_0-auc:0.844682\n",
      "\n",
      "[76]\tvalidation_0-auc:0.844680\n",
      "\n",
      "[77]\tvalidation_0-auc:0.844804\n",
      "\n",
      "[78]\tvalidation_0-auc:0.844816\n",
      "\n",
      "[79]\tvalidation_0-auc:0.844729\n",
      "\n",
      "[80]\tvalidation_0-auc:0.844724\n",
      "\n",
      "[81]\tvalidation_0-auc:0.844664\n",
      "\n",
      "[82]\tvalidation_0-auc:0.844991\n",
      "\n",
      "[83]\tvalidation_0-auc:0.845176\n",
      "\n",
      "[84]\tvalidation_0-auc:0.845237\n",
      "\n",
      "[85]\tvalidation_0-auc:0.845155\n",
      "\n",
      "[86]\tvalidation_0-auc:0.845209\n",
      "\n",
      "[87]\tvalidation_0-auc:0.845449\n",
      "\n",
      "[88]\tvalidation_0-auc:0.845573\n",
      "\n",
      "[89]\tvalidation_0-auc:0.845686\n",
      "\n",
      "[90]\tvalidation_0-auc:0.845843\n",
      "\n",
      "[91]\tvalidation_0-auc:0.845747\n",
      "\n",
      "[92]\tvalidation_0-auc:0.845820\n",
      "\n",
      "[93]\tvalidation_0-auc:0.845774\n",
      "\n",
      "[94]\tvalidation_0-auc:0.846050\n",
      "\n",
      "[95]\tvalidation_0-auc:0.846048\n",
      "\n",
      "[96]\tvalidation_0-auc:0.846004\n",
      "\n",
      "[97]\tvalidation_0-auc:0.846020\n",
      "\n",
      "[98]\tvalidation_0-auc:0.846140\n",
      "\n",
      "[99]\tvalidation_0-auc:0.846098\n",
      "\n",
      "[100]\tvalidation_0-auc:0.846119\n",
      "\n",
      "[101]\tvalidation_0-auc:0.846031\n",
      "\n",
      "[102]\tvalidation_0-auc:0.845981\n",
      "\n",
      "[103]\tvalidation_0-auc:0.845990\n",
      "\n",
      "[104]\tvalidation_0-auc:0.845728\n",
      "\n",
      "[105]\tvalidation_0-auc:0.845789\n",
      "\n",
      "[106]\tvalidation_0-auc:0.845809\n",
      "\n",
      "[107]\tvalidation_0-auc:0.845825\n",
      "\n",
      "[108]\tvalidation_0-auc:0.845768\n",
      "\n",
      "[109]\tvalidation_0-auc:0.845802\n",
      "\n",
      "[110]\tvalidation_0-auc:0.845974\n",
      "\n",
      "[111]\tvalidation_0-auc:0.846017\n",
      "\n",
      "[112]\tvalidation_0-auc:0.845867\n",
      "\n",
      "[113]\tvalidation_0-auc:0.845859\n",
      "\n",
      "[114]\tvalidation_0-auc:0.845851\n",
      "\n",
      "[115]\tvalidation_0-auc:0.845813\n",
      "\n",
      "[116]\tvalidation_0-auc:0.845674\n",
      "\n",
      "[117]\tvalidation_0-auc:0.845685\n",
      "\n",
      "[118]\tvalidation_0-auc:0.845913\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[98]\tvalidation_0-auc:0.846140\n",
      "\n",
      "\n",
      "Private Score 0.84602036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "best_params = {\n",
    "    'max_depth': int(best['max_depth']),\n",
    "    'min_child_weight': int(best['min_child_weight']),\n",
    "    'subsample': float(best['subsample']),\n",
    "    'colsample_bytree': float(best['colsample_bytree']),\n",
    "    'n_estimators': n_total_estimators,\n",
    "    'seed': seed,\n",
    "}\n",
    "\n",
    "def iter_learning_rates(i, n): \n",
    "    return learning_rates(\n",
    "        n, start=best['learning_rate_start'], end=best['learning_rate_end']\n",
    "    )[i]\n",
    "\n",
    "fit_params['learning_rates'] = iter_learning_rates\n",
    "\n",
    "clf = xgb.XGBClassifier(**best_params)\n",
    "clf.fit(X_train.values, y_train.values, **fit_params)\n",
    "\n",
    "score = roc_auc_score(y_test.values, clf.predict_proba(X_test.values, ntree_limit=clf.best_iteration)[:,1])\n",
    "\n",
    "print(\"Private Score %.8f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ids_test_, X_test_, y_test_ = transform(test)\n",
    "\n",
    "# Seriously, this must go in some preprocessing function!\n",
    "X_, y_ = skutils.random_subset(X_train_, y_train_, dims=[(0, fzeros), (1, 1.0)])\n",
    "\n",
    "fit_params['early_stopping_rounds'] = None\n",
    "fit_params['eval_set'] = None\n",
    "\n",
    "clf.fit(X_.values, y_.values, verbose=False, **fit_params)\n",
    "\n",
    "y_pred = clf.predict_proba(X_test_.values, ntree_limit=clf.best_iteration)\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":Ids_test_, \"TARGET\":y_pred[:,1]})\n",
    "submission.to_csv(\"submissions/submission_%s.csv\" % utils.timestamp(), index=False)\n",
    "\n",
    "# Public Score: 0.836881"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
